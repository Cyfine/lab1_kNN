{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with k-Nearest Neighbour Algorithm\n",
    "## Example 1: Improving Matches for A Dating Site with KNN\n",
    "### 1.1 Data Processing Part\n",
    "This part will load data from the file, then normalize the data.\n",
    "\n",
    "#### 1.1.1 file2matrix\n",
    "The training data given by Helen includes data points and label. In each line of the data file, first three numbers represent feature of the data object, while the fourth represents the label. The file2matrix is used to load the original feature of the training data and the labels for data object.\n",
    "\n",
    "As the training data is stored in txt file, we can first use the built in `open` function to load the file to the memory. fr is `TextIoWrapper` object, it has a `readlines()` method that can return `list` contains string of each line. Then we using `len` method to count the lines, so that we can initialize a np array having proper size to store the data. We iterate the list stores the line strings, to extract the numbers and write to original feature matrix and class_label_vector. And finally, it return the original feature matrix and class label vector\n",
    "\n",
    "The detailed explanations for each line of file2matrix are written in line comments of following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import operator\n",
    "# numpy.set_printoptions(threshold=np.inf)\n",
    "\n",
    "def file2matrix(filename):\n",
    "    # Load the file with given filename, and store in the variable fr\n",
    "    fr = open(filename)\n",
    "    #fr.readlines() read the txt file to list, the len method counts lines in the file,\n",
    "    number_of_lines = len(fr.readlines())\n",
    "    # define a 2d numpy array , to store the coordinate of the data points x\n",
    "    return_mat = zeros((number_of_lines, 3))\n",
    "    # used to store the label of data points, y\n",
    "    class_label_vector = []\n",
    "    index = 0\n",
    "    # here we open open the file repeatedly for reason\n",
    "    # If we do not open the file again we will get nothing from fr.readlines()\n",
    "    # As the previous fr.readlines() has move file pointer to the end of the file.\n",
    "    fr = open(filename)\n",
    "    for line in fr.readlines():\n",
    "        #trim the spaces at the head and tail of each lines\n",
    "        line = line.strip()\n",
    "        # the data points are divided using tab,\n",
    "        # split the string, and extract tokens from the line-string\n",
    "        list_from_line = line.split('\\t')\n",
    "        # the first three numbers are the original features\n",
    "        return_mat[index, :] = list_from_line[0:3]\n",
    "        # last number is the feature, stored in the class_label_vector\n",
    "        class_label_vector.append(int(list_from_line[-1]))\n",
    "        #the index is used to keep track of the row number, write to return_mat sequentially\n",
    "        index += 1\n",
    "    #return the original feature matrix and class label vector\n",
    "    return return_mat, class_label_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load original feature matrix `datingDataMat` and class label vector from the training data file. And print the nparray to see if the data is loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Original features\n",
      "[[4.0920000e+04 8.3269760e+00 9.5395200e-01]\n",
      " [1.4488000e+04 7.1534690e+00 1.6739040e+00]\n",
      " [2.6052000e+04 1.4418710e+00 8.0512400e-01]\n",
      " ...\n",
      " [2.6575000e+04 1.0650102e+01 8.6662700e-01]\n",
      " [4.8111000e+04 9.1345280e+00 7.2804500e-01]\n",
      " [4.3757000e+04 7.8826010e+00 1.3324460e+00]]\n",
      "\n",
      " Labels:\n",
      "[3, 2, 1, 1, 1, 1, 3, 3, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "datingDataMat, datingLabels = file2matrix('datingTestSet2.txt')\n",
    "print(\"\\n Original features\")\n",
    "print(datingDataMat)\n",
    "print(\"\\n Labels:\")\n",
    "print(datingLabels[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 autoNorm\n",
    "For the each feature from the training data, it has different scale. If we do not normalize the features and map the data of each feature into same scale, the classification will biased to the feature with larger scale.\n",
    "AutoNorm function automatically normalize data between 0 and 1 using max-min normalization.\n",
    "##### 1.1.2.1 Code and details\n",
    "The input parameter is the original feature data matrix. The  `min(0)` and `max(0)` will find out the minimum value and maximum value among all elements in each column (feature) of the data matrix. For the max function, without parameter will find the maximum element among all the element in the matrix. Using 0 as parameter will find out the largest value in each column and return a list of max value of each column. Using max(1) will find out the maximum value in each row. The minVals and maxVals are ndarray with length of 3.Containing the maximum and minimum value of each column. The minVals - maxVals will conduct element wise operation on the ndarray. And the ranges contains the range of each feature. The `shape` function of ndarray will return shape of the ndarray in tuple format. For our dataset matrix, its a tuple (rows, columns). And we obtain the number of rows using `dataset.shape[0]`. The `tile` function is used to construct ndarray with repeated components. The second parameter of  `tile` function, is array-like. Its indicates how the given ndarray is being repeated in the newly constructed ndarray. From left to the right, is the number of times repeated along each axis. `tile(minVals, (m,1))` will construct a matrix with `minVals` repeat m time along axis=0 and 1 times along axis=1. The result is m minVals array stacking form a matrix, having shape same as the `dataset` matrix. For ndarray, if the shape is the same, the arithmetic operators can be directly applied among arrays, and will conduct elementwise operation.\n",
    "```python\n",
    "    normDataset = dataset - tile(minVals, (m, 1))\n",
    "    normDataset = normDataset / tile(ranges, (m, 1))\n",
    "```\n",
    "Those to lines apply element wise operation on the the the dataset. The normDataset is the result of each element of datamatrix being max-min normalized. At the end, we return the result of, of normalized dataset matrix, and ranges and minVal vectors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def autoNorm(dataset:ndarray):\n",
    "    minVals = dataset.min(0)\n",
    "    maxVals = dataset.max(0)\n",
    "    ranges = maxVals - minVals\n",
    "    normDataset = zeros(shape(dataset))\n",
    "    m = dataset.shape[0]\n",
    "    normDataset = dataset - tile(minVals, (m, 1))\n",
    "    normDataset = normDataset / tile(ranges, (m, 1))\n",
    "    return normDataset, ranges, minVals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Normalized features:\n",
      "[[0.44832535 0.39805139 0.56233353]\n",
      " [0.15873259 0.34195467 0.98724416]\n",
      " [0.28542943 0.06892523 0.47449629]\n",
      " ...\n",
      " [0.29115949 0.50910294 0.51079493]\n",
      " [0.52711097 0.43665451 0.4290048 ]\n",
      " [0.47940793 0.3768091  0.78571804]]\n"
     ]
    }
   ],
   "source": [
    "normMat, ranges, minVals = autoNorm(datingDataMat)\n",
    "print('\\n Normalized features:')\n",
    "print(normMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Classification\n",
    "Here, will be the core part of this report. Classification using kNN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def classify0(inX, dataset, labels, k):\n",
    "    datasetSize = dataset.shape[0]\n",
    "    diffMat = tile(inX, (datasetSize, 1)) - dataset\n",
    "    sqDiffMat = diffMat ** 2\n",
    "    sqDistances = sqDiffMat.sum(axis=1)\n",
    "    distances = sqDistances ** 0.5\n",
    "    sortedDistIndices = distances.argsort()\n",
    "    classCount = {}\n",
    "    for i in range(k):\n",
    "        voteIlabels = labels[sortedDistIndices[i]]\n",
    "        classCount[voteIlabels] = classCount.get(voteIlabels, 0) + 1\n",
    "        sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " You will probably like this person:   in small doses\n"
     ]
    }
   ],
   "source": [
    "def classifyPerson():\n",
    "    resultList = ['not at all', ' in small doses', 'in large doses']\n",
    "    ffMiles = float(input('\\n Feature 1:'))\n",
    "    percentTats = float(input(\"\\n Feature 2:\"))\n",
    "    iceCream = float(input(\"\\n Feature 3:\"))\n",
    "    datingDataMat, datingLabels = file2matrix('datingTestSet2.txt')\n",
    "    normMat, ranges, minVals = autoNorm(datingDataMat)\n",
    "    inArr = array([ffMiles, percentTats, iceCream])\n",
    "    classifier_result = classify0((inArr - minVals) / ranges, normMat, datingLabels, 3)\n",
    "    print(\"\\n You will probably like this person: \", resultList[classifier_result - 1])\n",
    "\n",
    "\n",
    "classifyPerson()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from os import listdir\n",
    "\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def img2Vector(filename):\n",
    "    returnVect = zeros((1, 1024))\n",
    "    fr = open(filename)\n",
    "    for i in range(32):\n",
    "        lineStr = fr.readline()\n",
    "        for j in range(32):\n",
    "            returnVect[0, 32 * i + j] = int(lineStr[j])\n",
    "    return returnVect\n",
    "\n",
    "\n",
    "print(img2Vector(\"testDigits/0_13.txt\")[0][0:32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def formulateTrainingData():\n",
    "    hwLabels = []\n",
    "    trainingFilelist = listdir('trainingDigits')\n",
    "    m = len(trainingFilelist)\n",
    "    trainingMat = zeros((m, 1024))\n",
    "    for i in range(m):\n",
    "        fileNameStr = trainingFilelist[i]\n",
    "        fileStr = fileNameStr.split('.')[0]\n",
    "        classNumStr = int(fileStr.split('_')[0])\n",
    "        hwLabels.append(classNumStr)\n",
    "        trainingMat[i, :] = img2Vector('trainingDigits/%s' % fileNameStr)\n",
    "\n",
    "    return trainingMat, hwLabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainingMat, hwLabels = formulateTrainingData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def handwritingClassTest(trainingMat, hwLabels):\n",
    "    testFileList = listdir('testDigits')\n",
    "    errorCount = 0.0\n",
    "    mTest = len(testFileList)\n",
    "    for i in range(mTest):\n",
    "        fileNameStr = testFileList[i]\n",
    "        fileStr = fileNameStr.split('.')[0]\n",
    "        classNumStr = int(fileStr.split('_')[0])\n",
    "        vectorUnderTest = img2Vector('testDigits/%s' % fileNameStr)\n",
    "        classfierResult = classify0(vectorUnderTest, trainingMat, hwLabels, 3)\n",
    "        if classfierResult != classNumStr:\n",
    "            errorCount += 1.0\n",
    "\n",
    "    print(\"\\n The total number of errors is: %d\" % errorCount)\n",
    "    print(\"\\n The total error rate is %f\" % (errorCount / float(mTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The total number of errors is: 11\n",
      "\n",
      " The total error rate is 0.011628\n"
     ]
    }
   ],
   "source": [
    "handwritingClassTest(trainingMat, hwLabels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
